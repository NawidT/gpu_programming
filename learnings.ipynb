{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MSXCSbp_Djn",
        "outputId": "5bbbf446-19cd-4812-af5e-709ffc1cfb78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing code.h\n"
          ]
        }
      ],
      "source": [
        "%%writefile code.h\n",
        "\n",
        "int multiply(int a, int b);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yuwWyPp_Djn",
        "outputId": "68d68d1b-e18e-4153-e7b1-52f0bda176f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing code.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile code.cpp\n",
        "\n",
        "#include \"code.h\"\n",
        "using namespace std;\n",
        "\n",
        "int multiply(int a, int b) {\n",
        "  return a * b;\n",
        "};"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yjm_A-oA_Djn",
        "outputId": "b277070c-7e1e-4548-e1fe-277942f5f849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing main.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.cpp\n",
        "\n",
        "#include <iostream>\n",
        "using namespace std\n",
        "#include \"code.h\"\n",
        "\n",
        "int main() {\n",
        "  cout << multiply(6,7) << '\\n';\n",
        "  return 0;\n",
        "};"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAMLIr22_Djo",
        "outputId": "7268bfa0-0f4e-404c-87c8-eb1cd8cf2d47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mcode.cpp:3:17: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1musing directive refers to implicitly-defined namespace 'std'\u001b[0m\n",
            "using namespace std;\n",
            "\u001b[0;1;32m                ^\n",
            "\u001b[0m1 warning generated.\n",
            "42\n"
          ]
        }
      ],
      "source": [
        "!g++ main.cpp code.cpp -o main\n",
        "!./main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM-28pCv_Djo",
        "outputId": "1993b157-4c26-47ed-d094-0a2619984bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukJ2Kbqw_Djo",
        "outputId": "9b709bc7-2bc1-4aa3-ffcb-965dd19ebc24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile test.cu\n",
        "\n",
        "#include <cstdio>\n",
        "#define cudaCheckError() { cudaError_t e=cudaGetLastError(); if(e!=cudaSuccess) printf(\"CUDA error %s\\n\", cudaGetErrorString(e)); }\n",
        "\n",
        "__global__ void helloCUDA() {\n",
        "    printf(\"Hello from CUDA kernel cuda!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    helloCUDA<<<1,1>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaCheckError();\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e61gUva7_Djo",
        "outputId": "b607115e-998b-4118-8b62-0c691ebf0b3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from CUDA kernel cuda!\n"
          ]
        }
      ],
      "source": [
        "!nvcc -arch=sm_75 test.cu -o test_cuda\n",
        "!./test_cuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streaming.cu\n",
        "\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void vectorAdd(const float *A, const float *B, float *C, int numElems) {\n",
        "    // conditional in place when num threads exceed needed operations.\n",
        "    // E.g 256 threads/block * 4 blocks = 1024 threads, but only 1000 needed\n",
        "    // Extra 24 threads will be ignored\n",
        "    if (threadIdx.x >= numElems) {\n",
        "        return;\n",
        "    }\n",
        "    for (int i = 0; i < numElems; i++) {\n",
        "      C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // PROBLEM: optimize a large vector addition process using streaming and paralellism\n",
        "\n",
        "    // currently in realms of host (CPU) so can use non-cuda operations\n",
        "    int numRows = 50000;\n",
        "    size_t size = numRows * sizeof(float);\n",
        "    float *h_A, *h_B, *h_C;\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_A = (float *) malloc(size);\n",
        "    h_B = (float *) malloc(size);\n",
        "    h_C = (float *) malloc(size);\n",
        "\n",
        "    // Initialize host arrays\n",
        "    for (int i = 0; i < numRows; ++i) {\n",
        "        h_A[i] = rand() / (float)RAND_MAX;\n",
        "        h_B[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate memory for device arrays\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "\n",
        "    // create streams to async-ly copy data to device\n",
        "    cudaStream_t stream1, stream2;\n",
        "\n",
        "    cudaStreamCreate(&stream1);\n",
        "    cudaStreamCreate(&stream2);\n",
        "\n",
        "    cudaMemcpyAsync(d_A, h_A, size, cudaMemcpyHostToDevice, stream1);\n",
        "    cudaMemcpyAsync(d_B, h_B, size, cudaMemcpyHostToDevice, stream2);\n",
        "\n",
        "    // Launch kernel<<<blocksPerGrid, threadsPerBlock, 0, stream1>>>(d_A, d_B, d_C, numRows);\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (numRows + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(h_A, h_B, h_C, size);\n",
        "\n",
        "\n",
        "    // copy data back to host\n",
        "    cudaMemcpyAsync(h_C, d_C, size, cudaMemcpyDeviceToHost, stream1);\n",
        "\n",
        "    // clean up\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "};\n",
        "\n"
      ],
      "metadata": {
        "id": "qCi8Wf3JJIYl",
        "outputId": "ec67d34c-3c8e-449f-a1c4-713c6e1fe3c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streaming.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 streaming.cu -o stream\n",
        "!./stream"
      ],
      "metadata": {
        "id": "RbBfNGp1KWAi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile image_cv_ops.cu\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "#include <opencv2/opencv.hpp>\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void apply_gaussian_blur(const float *image, float *out_image, int num_pixels) {\n",
        "    // conditional in place when num threads exceed needed operations.\n",
        "    if (threadIdx.x >= num_pixels) {\n",
        "        return;\n",
        "    }\n",
        "    int pixel_index = threadIdx.x;\n",
        "\n",
        "    // create the gaussian kernel\n",
        "    float kernel[3][3] = {\n",
        "        {1.0/16, 2.0/16, 1.0/16},\n",
        "        {2.0/16, 4.0/16, 2.0/16},\n",
        "        {1.0/16, 2.0/16, 1.0/16}\n",
        "    };\n",
        "\n",
        "    // apply blur to image, pasting to out_image\n",
        "    int kernel_size = 3;\n",
        "    float sum = 0;\n",
        "    for (int i = 0; i < kernel_size; i++) {\n",
        "        for (int j  = 0; j < kernel_size; j++) {\n",
        "            int image_index = pixel_index + i * kernel_size + j;\n",
        "            sum += image[image_index] * kernel[i][j];\n",
        "        }\n",
        "    }\n",
        "    out_image[pixel_index] = sum;\n",
        "}\n",
        "\n",
        "void run_gaussian_blur(const float *image, float *out_image, int num_pixels) {\n",
        "    // copy image to VRAM (shared memory)\n",
        "    size_t size_pixels = num_pixels * sizeof(float);\n",
        "    float *d_image, *d_out_image;\n",
        "    cudaMalloc(&d_image, size_pixels);\n",
        "    cudaMalloc(&d_out_image, size_pixels);\n",
        "    cudaMemcpy(d_image, image, size_pixels, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // apply gaussian blur to image\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (num_pixels + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    apply_gaussian_blur<<<blocksPerGrid, threadsPerBlock>>>(d_image, d_out_image, num_pixels);\n",
        "\n",
        "    // copy image back to host\n",
        "    cudaMemcpy(out_image, d_out_image, size_pixels, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // clean up\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_out_image);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // open image using cv::imread()\n",
        "    cv::Mat image = cv::imread(\"1b_cat.bmp\", cv::IMREAD_GRAYSCALE);\n",
        "    if (image.empty()) {\n",
        "        printf(\"Could not open or find the image\\n\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    int num_pixels = image.rows * image.cols;\n",
        "    float *h_image = (float*) image.data;\n",
        "    float *h_out_image = (float*) malloc(num_pixels * sizeof(float));\n",
        "\n",
        "    // apply gaussian blur to image\n",
        "    run_gaussian_blur(h_image, h_out_image, num_pixels);\n",
        "\n",
        "    // convert the output image back to cv::Mat\n",
        "    cv::Mat out_image(image.size(), image.type(), h_out_image);\n",
        "    cv::imwrite(\"blurred_image.jpg\", out_image);\n",
        "\n",
        "    // clean up\n",
        "    free(h_out_image);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "eKjXafKJ6iGk",
        "outputId": "b2a4a895-1035-4887-8af0-c4e86c77f7bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting image_cv_ops.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 image_cv_ops.cu -o cv_ops -I/usr/include/opencv4 -w -L/usr/lib -lopencv_core -lopencv_imgcodecs -lopencv_highgui -lopencv_imgproc > /dev/null 2>&1\n",
        "!./cv_ops"
      ],
      "metadata": {
        "id": "gpZvcK7E68W_"
      },
      "execution_count": 86,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}